{
	"task_name": ["MountainCarLoCA"],
	"agent_name": ["NonlinearDynaQ"],
	"optimizer_name": ["Adam"],
	"use_target_network": [true],
	"eval_epsilon": [0],
	"q_body": ["FCBody"],
	"q_body_network": [[64, 64, 64, 64]],
	"q_body_gate": ["tanh"],
	"s_body": ["FCBody"],
	"s_body_network": [[64, 64, 64, 64]],
	"s_body_gate": ["tanh"],
	"r_body": ["FCBody"],
	"r_body_network": [[64, 64, 64, 64]],
	"r_body_gate": ["tanh"],
	"t_body": ["FCBody"],
	"t_body_network": [[64, 64, 64, 64]],
	"t_body_gate": ["tanh"],
	"output_layer_bias": [true],
	"discount": [0.99],
	"timeout": [500],
	"log_interval": [10000],
	"if_eval_episodes": [true],
	"eval_interval": [10000],
	"eval_episodes": [10],
	"network_name": ["NonLinearDynaQNet"],
	"num_learning_steps": [5],
	"num_planning_steps": [5],
	"phase1_steps": [1500000],
	"phase2_steps": [1500000],
	"max_steps": [3000000],
	"planning_buffer_size": [3000000],
	"learning_batch_size": [32],
	"planning_batch_size": [32],
	"force": [0.001],
	"terminal2_radius": [0.07],
	"action_stochasticity": [0.0],
	"reward_emphasis": [true, false],
	"lr": [5e-7, 1e-6, 5e-6, 1e-5, 5e-5],
	"model_lr": [1e-6, 5e-6, 1e-5, 5e-5, 1e-4],
	"epsilon": [0.1, 0.5, 1.0],
	"learning_buffer_size": [300000, 3000000]
}
